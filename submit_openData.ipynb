{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44886638",
   "metadata": {},
   "source": [
    "# How users feel? A sentiment Analysis on Twitter v3\n",
    "## Giacomo Manfucci\n",
    "### A challenge from Open Data Playgroud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "100f87c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#    Salve a tutto il team di Open Data Playgroud,\n",
    "#    Sono Giacomo Manfucci, uno studente di statistica presso l'Università degli Studi di Firenze.\n",
    "#    Questo è il codice python del mio tentativo \n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a66a5",
   "metadata": {},
   "source": [
    "## Importo il train dataset e opero una breve esplorazione dei dati\n",
    "\n",
    "### Due caratteristiche\n",
    "\n",
    "     1   tweet:\n",
    "     \n",
    "         La componente testuale del tweet su cui fare analisi del sentiment.\n",
    "         \n",
    "     2   label:\n",
    "     \n",
    "         L'etichetta che classifica il tweet:\n",
    "             0 -> negative\n",
    "             1 -> neutral\n",
    "             2 -> positive\n",
    "            \n",
    "In realtà mi accorgerò dopo che le etichette sono 4 e quindi lavorerò su queste 4 etichette che vanno da 0 a 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e02de3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No but that's so cute. Atsu was probably shy a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rooneys fucking untouchable isn't he? Been fuc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it's pretty depressing when u hit pan on ur fa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  “Worry is a down payment on a problem you may ...      2\n",
       "1  My roommate: it's okay that we can't spell bec...      0\n",
       "2  No but that's so cute. Atsu was probably shy a...      1\n",
       "3  Rooneys fucking untouchable isn't he? Been fuc...      0\n",
       "4  it's pretty depressing when u hit pan on ur fa...      3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Importo il file e lo salvo come un df pandas\n",
    "df_train = pd.read_csv(r\"C:\\Users\\giaco\\OneDrive\\Desktop\\Sfide_ML\\dataset_OpenDataPlay\\train_complete.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "96176544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3631, 2)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Vediamo quante righe e colonne il df ha\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0320a821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1560\n",
      "3     944\n",
      "1     805\n",
      "2     322\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Costruisco la tabella di frequenze delle etichette\n",
    "freq = df_train['label'].value_counts() \n",
    "print(freq) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a4e623",
   "metadata": {},
   "source": [
    "## Voglio ora ripulire il testo dei tweet\n",
    "\n",
    "Voglio eliminare qualsiasi carattere non testo, tranne per le faccine che decido di mettere alla fine del testo. Uso quindi delle espressioni regolari che mi permettano di fare questo. Anche se non è una scelta elegante (elimino anche la punteggiatura e l'ordine), opto per la scelta più immediata e vedo come funziona.\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97724402",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo così la mia funzione di gestione delle espressioni regolari\n",
    "\n",
    "#Questa funzione mi eliminerà eventuali rimasugli di HTML (non ci dovrebbero essere),\n",
    "#poi mi trasferisce le emoticon alla fine del tweet e infine\n",
    "#mi porta tutto il testo in minuscolo e rimuove qualche altro particolare\n",
    "#\n",
    "\n",
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
    "                           text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
    "            ' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8f29698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>worry is a down payment on a problem you may ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>my roommate it s okay that we can t spell beca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no but that s so cute atsu was probably shy ab...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rooneys fucking untouchable isn t he been fuck...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>it s pretty depressing when u hit pan on ur fa...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0   worry is a down payment on a problem you may ...      2\n",
       "1  my roommate it s okay that we can t spell beca...      0\n",
       "2  no but that s so cute atsu was probably shy ab...      1\n",
       "3  rooneys fucking untouchable isn t he been fuck...      0\n",
       "4  it s pretty depressing when u hit pan on ur fa...      3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Trasformo così i miei dati testuali tramite la funzione appena costruita\n",
    "df_train['tweet'] = df_train['tweet'].apply(preprocessor)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7757494",
   "metadata": {},
   "source": [
    "# Addestramento, ottimizzazione e stima delle prestazioni\n",
    "\n",
    "## Addestramento\n",
    "\n",
    "Addestrerò il mio modello usando il metodo bag-of-words con rappresentazione 1-gram (rendendo quindi giustificata la perdita di ordine che verrà effettuata), inoltre userò la valutazione della rilevanza delle parole tramite la tecnica Term Frequency - Inverse Document Frequency (TF-IDF). \n",
    "\n",
    "L'algoritmo di classificazione sarà quello a regressione logistica per problemi multi-classe (OvA, One vs All).\n",
    "\n",
    "## Ottimizzazione \n",
    "\n",
    "Ottimizzerò il mio modello tramite la ricerca a griglia.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "51a320cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definisco la tokenizzazione classica e quella di stemming di Porter per separare le parole.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c25926e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divido il mio dataset in un dataset di addestramento e uno di test \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train['tweet'], df_train['label'],         \n",
    "                                                test_size=0.3,          \n",
    "                                                random_state=0, \n",
    "                                                stratify=df_train['label'])             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "efe3e140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('vect',\n",
       "                                        TfidfVectorizer(lowercase=False)),\n",
       "                                       ('clf',\n",
       "                                        LogisticRegression(multi_class='ovr',\n",
       "                                                           random_state=0,\n",
       "                                                           solver='liblinear'))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid=[{'clf__C': [1.0, 10.0, 100.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__ngram_range': [(1, 1)],\n",
       "                          'vect__stop_words': [None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x000001DC7189DB80>,\n",
       "                                              <function tokenizer_porter at 0x000001DC7189D9D0>]},\n",
       "                         {'clf__C': [1.0, 10.0, 100.0],\n",
       "                          'clf__penalty': ['l1', 'l2'],\n",
       "                          'vect__ngram_range': [(1, 1)], 'vect__norm': [None],\n",
       "                          'vect__stop_words': [None],\n",
       "                          'vect__tokenizer': [<function tokenizer at 0x000001DC7189DB80>,\n",
       "                                              <function tokenizer_porter at 0x000001DC7189D9D0>],\n",
       "                          'vect__use_idf': [False]}],\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Addestro e ottimizzo gli iperparametri del mio modello di classificazione, di analisi del sentiment\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "\n",
    "#Questa è la lista di dizionari degli iperparametri che mi servirà per la ricerca a griglia\n",
    "\n",
    "param_grid = [{'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              {'vect__ngram_range': [(1, 1)],\n",
    "               'vect__stop_words': [None],\n",
    "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "               'vect__use_idf':[False],\n",
    "               'vect__norm':[None],\n",
    "               'clf__penalty': ['l1', 'l2'],\n",
    "               'clf__C': [1.0, 10.0, 100.0]},\n",
    "              ]\n",
    "\n",
    "#Costruisco quindi la mia breve Pipeline\n",
    "\n",
    "lr_tfidf = Pipeline([('vect', tfidf),\n",
    "                     ('clf', LogisticRegression(random_state=0, solver='liblinear', multi_class='ovr'))])\n",
    "\n",
    "#Faccio la ricerca a griglia con una convalida incrociata con k = 10, valore abbastanza standard, forse potevo usare un k<10, \n",
    "#ma va bene così.\n",
    "\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=10,\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1) #Ho impostato n_jobs = -1 per chi ha la fortuna di poter lavorare in parallelo\n",
    "\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "68940ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter set: {'clf__C': 1.0, 'clf__penalty': 'l1', 'vect__ngram_range': (1, 1), 'vect__norm': None, 'vect__stop_words': None, 'vect__tokenizer': <function tokenizer_porter at 0x000001DC7189D9D0>, 'vect__use_idf': False} \n",
      "CV Accuracy: 0.704\n",
      "Test Accuracy: 0.697\n"
     ]
    }
   ],
   "source": [
    "#Stampo a schermo i migliori parametri e le relative performance \n",
    "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n",
    "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)\n",
    "\n",
    "#Quindi costruisco il mio modello con i valori degli iperparametri migliori e misuro la performance.\n",
    "clf = gs_lr_tfidf.best_estimator_\n",
    "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defee7ac",
   "metadata": {},
   "source": [
    "## Riaddestro ora sull'intero dataset \n",
    "Come buona norma. Non ricordo se l'implementazione precedente lo fa di default (non credo), comunque nel dubbio lo faccio manualmente, tanto il costo computazionale non è alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "009ae61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect',\n",
       "                 TfidfVectorizer(lowercase=False, norm=None,\n",
       "                                 tokenizer=<function tokenizer_porter at 0x000001DC7189D9D0>,\n",
       "                                 use_idf=False)),\n",
       "                ('clf',\n",
       "                 LogisticRegression(multi_class='ovr', penalty='l1',\n",
       "                                    random_state=0, solver='liblinear'))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df_train['tweet'], df_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc02bf68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8779816513761468"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Questa operazione è inutile ai fini del controllo della performance, ma era per controllare che tutto fosse in ordine\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee78ae",
   "metadata": {},
   "source": [
    "# Importo ora il dataset sul quale farò le mie predizioni del sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc07cc25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user Interesting choice of words... Are you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My visit to hospital for care triggered #traum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What makes you feel #joyful? \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet\n",
       "0  #Deppression is real. Partners w/ #depressed p...\n",
       "1  @user Interesting choice of words... Are you c...\n",
       "2  My visit to hospital for care triggered #traum...\n",
       "3  @user Welcome to #MPSVT! We are delighted to h...\n",
       "4                    What makes you feel #joyful? \\n"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(r'C:\\Users\\giaco\\OneDrive\\Desktop\\Sfide_ML\\dataset_OpenDataPlay\\test_text.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "X_sub = pd.DataFrame({'tweet': lines})\n",
    "\n",
    "X_sub.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e54f68bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1421, 1)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd91c1",
   "metadata": {},
   "source": [
    "### Dopo aver letto il file e portato in un df pandas ora faccio le predizioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "09eed8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      0\n",
       "1      0\n",
       "2      3\n",
       "3      1\n",
       "4      3"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sub = clf.predict(X_sub['tweet'])\n",
    "y_sub = pd.DataFrame({'label': y_sub})\n",
    "\n",
    "y_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d851a4",
   "metadata": {},
   "source": [
    "### Unisco in un unico df X_sub e y_sub e esporto il df in un file csv come richiesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fe018420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Deppression is real. Partners w/ #depressed p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user Interesting choice of words... Are you c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My visit to hospital for care triggered #traum...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@user Welcome to #MPSVT! We are delighted to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What makes you feel #joyful? \\n</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet  label\n",
       "0  #Deppression is real. Partners w/ #depressed p...      0\n",
       "1  @user Interesting choice of words... Are you c...      0\n",
       "2  My visit to hospital for care triggered #traum...      3\n",
       "3  @user Welcome to #MPSVT! We are delighted to h...      1\n",
       "4                    What makes you feel #joyful? \\n      3"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sub = pd.concat([X_sub, y_sub], axis=1)\n",
    "\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42d28a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.to_csv(r\"C:\\Users\\giaco\\OneDrive\\Desktop\\Sfide_ML\\submits_OpenDataPlay\\submit_1_ODP.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d73e502",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
